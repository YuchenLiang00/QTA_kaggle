{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ca402f",
   "metadata": {
    "papermill": {
     "duration": 0.001558,
     "end_time": "2023-10-10T15:14:24.375869",
     "exception": false,
     "start_time": "2023-10-10T15:14:24.374311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# All credits to this notebook: https://www.kaggle.com/code/renatoreggiani/optv-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3b51c4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-10T15:14:24.380162Z",
     "iopub.status.busy": "2023-10-10T15:14:24.379665Z",
     "iopub.status.idle": "2023-10-10T15:17:44.651972Z",
     "shell.execute_reply": "2023-10-10T15:17:44.651200Z"
    },
    "papermill": {
     "duration": 200.27677,
     "end_time": "2023-10-10T15:17:44.653871",
     "exception": false,
     "start_time": "2023-10-10T15:14:24.377101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from warnings import simplefilter\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "is_train = False\n",
    "is_infer = True\n",
    "N_Folds = 4\n",
    "\n",
    "train = pd.read_csv('../input/optiver-trading-at-the-close/train.csv')\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].std() + train.groupby('stock_id')['ask_size'].std()\n",
    "train = train.dropna(subset=['target'])\n",
    "\n",
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    df['bid_ask_volume_diff'] = df['ask_size'] - df['bid_size']\n",
    "    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + df['ask_size']\n",
    "    df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "    df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0)\n",
    "        \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        'date_id', \n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    return df\n",
    "\n",
    "y = train['target'].values\n",
    "X = feat_eng(train.drop(columns='target'))\n",
    "\n",
    "y_min = np.min(y)\n",
    "y_max = np.max(y)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.018,\n",
    "    'max_depth': 9,\n",
    "    'n_estimators': 600,\n",
    "    'num_leaves': 440,\n",
    "    'objective': 'mae',\n",
    "    'random_state': 42,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01\n",
    "}\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=N_Folds, shuffle=True, random_state=42)\n",
    "mae_scores = []\n",
    "\n",
    "if is_train:\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "        m = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=50, early_stopping_rounds=50)\n",
    "        print(f\"Fold {fold+1} Trainning finished.\")\n",
    "\n",
    "        model_filename = f\"model_fold_{fold+1}.pkl\"\n",
    "        joblib.dump(m, model_filename)\n",
    "        y_pred_valid = m.predict(X_valid)\n",
    "\n",
    "        y_pred_valid = np.nan_to_num(y_pred_valid)\n",
    "        y_valid = np.nan_to_num(y_valid)\n",
    "        mae = mean_absolute_error(y_valid, y_pred_valid)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # 计算五折平均的MAE\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    print(f\"5 fold MAE: {average_mae}\")\n",
    "\n",
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "if is_infer:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "\n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        feat = feat_eng(test)\n",
    "        fold_prediction = 0\n",
    "        for fold in range(0, N_Folds):\n",
    "            model_filename = f\"/kaggle/input/lgb-models-optv2/model_fold_{fold+1}.pkl\"\n",
    "            m = joblib.load(model_filename)\n",
    "            fold_prediction += m.predict(feat)   \n",
    "        \n",
    "        fold_prediction /= N_Folds\n",
    "        fold_prediction = zero_sum(fold_prediction, test.loc[:,'bid_size'] + test.loc[:,'ask_size'])\n",
    "        clipped_predictions = np.clip(fold_prediction, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 203.520244,
   "end_time": "2023-10-10T15:17:45.476580",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-10T15:14:21.956336",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
